# HFT Arbitrage Engine Alert Rules
# Critical alerts for high-frequency trading operations

groups:
  - name: hft_arbitrage_alerts
    rules:
      # Latency alerts - critical for HFT
      - alert: HighExecutionLatency
        expr: hft_execution_latency_ms > 100
        for: 30s
        labels:
          severity: warning
          component: execution
        annotations:
          summary: "High execution latency detected"
          description: "Execution latency is {{ $value }}ms, exceeding 100ms threshold"

      - alert: CriticalExecutionLatency  
        expr: hft_execution_latency_ms > 500
        for: 10s
        labels:
          severity: critical
          component: execution
        annotations:
          summary: "Critical execution latency detected"
          description: "Execution latency is {{ $value }}ms, exceeding 500ms critical threshold"

      # System health alerts
      - alert: ArbitrageEngineDown
        expr: up{job="hft_arbitrage"} == 0
        for: 30s
        labels:
          severity: critical
          component: engine
        annotations:
          summary: "Arbitrage engine is not running"
          description: "The HFT arbitrage engine has been down for more than 30 seconds"

      # WebSocket connectivity alerts
      - alert: WebSocketDisconnected
        expr: hft_websocket_connected == 0
        for: 1m
        labels:
          severity: warning
          component: ws
        annotations:
          summary: "WebSocket connection lost"
          description: "WebSocket connection to {{ $labels.exchange }} has been lost"

      # Order execution alerts
      - alert: HighOrderFailureRate
        expr: rate(hft_orders_failed_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          component: orders
        annotations:
          summary: "High order failure rate"
          description: "Order failure rate is {{ $value | humanizePercentage }} over the last 5 minutes"

      # Opportunity detection alerts
      - alert: LowOpportunityDetection
        expr: rate(hft_opportunities_detected_total[10m]) < 0.01
        for: 5m
        labels:
          severity: warning
          component: detector
        annotations:
          summary: "Low arbitrage opportunity detection"
          description: "Only {{ $value }} opportunities detected per second over last 10 minutes"

      # Resource usage alerts
      - alert: HighMemoryUsage
        expr: hft_memory_usage_bytes / (1024 * 1024 * 1024) > 2
        for: 5m
        labels:
          severity: warning
          component: system
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}GB"

      # Push Gateway health
      - alert: PushGatewayDown
        expr: up{job="pushgateway"} == 0
        for: 1m
        labels:
          severity: critical
          component: monitoring
        annotations:
          summary: "Push Gateway is down"
          description: "Prometheus Push Gateway has been unreachable for more than 1 minute"

  - name: infrastructure_alerts
    rules:
      # Prometheus system alerts
      - alert: PrometheusConfigReloadFailed
        expr: prometheus_config_last_reload_successful == 0
        for: 1m
        labels:
          severity: warning
          component: prometheus
        annotations:
          summary: "Prometheus configuration reload failed"
          description: "Prometheus configuration reload has been failing"

      - alert: PrometheusTargetDown
        expr: up == 0
        for: 2m
        labels:
          severity: warning
          component: monitoring
        annotations:
          summary: "Prometheus target down"
          description: "Target {{ $labels.job }} {{ $labels.instance }} has been down for more than 2 minutes"